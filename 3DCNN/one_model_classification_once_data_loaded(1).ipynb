{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeDuJrEFQtDh",
        "outputId": "d0d93565-ea35-4169-84c0-972932bfe37b",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Binvox Read Write\n",
        "#  Copyright (C) 2012 Daniel Maturana\n",
        "#  This file is part of binvox-rw-py.\n",
        "#\n",
        "#  binvox-rw-py is free software: you can redistribute it and/or modify\n",
        "#  it under the terms of the GNU General Public License as published by\n",
        "#  the Free Software Foundation, either version 3 of the License, or\n",
        "#  (at your option) any later version.\n",
        "#\n",
        "#  binvox-rw-py is distributed in the hope that it will be useful,\n",
        "#  but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
        "#  GNU General Public License for more details.\n",
        "#\n",
        "#  You should have received a copy of the GNU General Public License\n",
        "#  along with binvox-rw-py. If not, see <http://www.gnu.org/licenses/>.\n",
        "#\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class Voxels(object):\n",
        "    \"\"\" Holds a binvox model.\n",
        "    data is either a three-dimensional numpy boolean array (dense representation)\n",
        "    or a two-dimensional numpy float array (coordinate representation).\n",
        "\n",
        "    dims, translate and scale are the model metadata.\n",
        "\n",
        "    dims are the voxel dimensions, e.g. [32, 32, 32] for a 32x32x32 model.\n",
        "\n",
        "    scale and translate relate the voxels to the original model coordinates.\n",
        "\n",
        "    To translate voxel coordinates i, j, k to original coordinates x, y, z:\n",
        "\n",
        "    x_n = (i+.5)/dims[0]\n",
        "    y_n = (j+.5)/dims[1]\n",
        "    z_n = (k+.5)/dims[2]\n",
        "    x = scale*x_n + translate[0]\n",
        "    y = scale*y_n + translate[1]\n",
        "    z = scale*z_n + translate[2]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data, dims, translate, scale, axis_order):\n",
        "        self.data = data\n",
        "        self.dims = dims\n",
        "        self.translate = translate\n",
        "        self.scale = scale\n",
        "        assert (axis_order in ('xzy', 'xyz'))\n",
        "        self.axis_order = axis_order\n",
        "\n",
        "    def clone(self):\n",
        "        data = self.data.copy()\n",
        "        dims = self.dims[:]\n",
        "        translate = self.translate[:]\n",
        "        return Voxels(data, dims, translate, self.scale, self.axis_order)\n",
        "\n",
        "    def write(self, fp):\n",
        "        write(self, fp)\n",
        "\n",
        "def read_header(fp):\n",
        "    \"\"\" Read binvox header. Mostly meant for internal use.\n",
        "    \"\"\"\n",
        "    line = fp.readline().strip()\n",
        "    if not line.startswith(b'#binvox'):\n",
        "        raise IOError('Not a binvox file')\n",
        "    dims = list(map(int, fp.readline().strip().split(b' ')[1:]))\n",
        "    translate = list(map(float, fp.readline().strip().split(b' ')[1:]))\n",
        "    scale = list(map(float, fp.readline().strip().split(b' ')[1:]))[0]\n",
        "    line = fp.readline()\n",
        "    return dims, translate, scale\n",
        "\n",
        "def read_as_3d_array(fp, fix_coords=True):\n",
        "    \"\"\" Read binary binvox format as array.\n",
        "\n",
        "    Returns the model with accompanying metadata.\n",
        "\n",
        "    Voxels are stored in a three-dimensional numpy array, which is simple and\n",
        "    direct, but may use a lot of memory for large models. (Storage requirements\n",
        "    are 8*(d^3) bytes, where d is the dimensions of the binvox model. Numpy\n",
        "    boolean arrays use a byte per element).\n",
        "\n",
        "    Doesn't do any checks on input except for the '#binvox' line.\n",
        "    \"\"\"\n",
        "    dims, translate, scale = read_header(fp)\n",
        "    raw_data = np.frombuffer(fp.read(), dtype=np.uint8)\n",
        "    # if just using reshape() on the raw data:\n",
        "    # indexing the array as array[i,j,k], the indices map into the\n",
        "    # coords as:\n",
        "    # i -> x\n",
        "    # j -> z\n",
        "    # k -> y\n",
        "    # if fix_coords is true, then data is rearranged so that\n",
        "    # mapping is\n",
        "    # i -> x\n",
        "    # j -> y\n",
        "    # k -> z\n",
        "    values, counts = raw_data[::2], raw_data[1::2]\n",
        "    data = np.repeat(values, counts).astype(bool)\n",
        "    data = data.reshape(dims)\n",
        "    if fix_coords:\n",
        "        # xzy to xyz TODO the right thing\n",
        "        data = np.transpose(data, (0, 2, 1))\n",
        "        axis_order = 'xyz'\n",
        "    else:\n",
        "        axis_order = 'xzy'\n",
        "    return Voxels(data, dims, translate, scale, axis_order)\n",
        "\n",
        "def read_as_coord_array(fp, fix_coords=True):\n",
        "    \"\"\" Read binary binvox format as coordinates.\n",
        "\n",
        "    Returns binvox model with voxels in a \"coordinate\" representation, i.e.  an\n",
        "    3 x N array where N is the number of nonzero voxels. Each column\n",
        "    corresponds to a nonzero voxel and the 3 rows are the (x, z, y) coordinates\n",
        "    of the voxel.  (The odd ordering is due to the way binvox format lays out\n",
        "    data).  Note that coordinates refer to the binvox voxels, without any\n",
        "    scaling or translation.\n",
        "\n",
        "    Use this to save memory if your model is very sparse (mostly empty).\n",
        "\n",
        "    Doesn't do any checks on input except for the '#binvox' line.\n",
        "    \"\"\"\n",
        "    dims, translate, scale = read_header(fp)\n",
        "    raw_data = np.frombuffer(fp.read(), dtype=np.uint8)\n",
        "\n",
        "    values, counts = raw_data[::2], raw_data[1::2]\n",
        "\n",
        "    sz = np.prod(dims)\n",
        "    index, end_index = 0, 0\n",
        "    end_indices = np.cumsum(counts)\n",
        "    indices = np.concatenate(([0], end_indices[:-1])).astype(end_indices.dtype)\n",
        "\n",
        "    values = values.astype(np.bool)\n",
        "    indices = indices[values]\n",
        "    end_indices = end_indices[values]\n",
        "\n",
        "    nz_voxels = []\n",
        "    for index, end_index in zip(indices, end_indices):\n",
        "        nz_voxels.extend(range(index, end_index))\n",
        "    nz_voxels = np.array(nz_voxels)\n",
        "    # TODO are these dims correct?\n",
        "    # according to docs,\n",
        "    # index = x * wxh + z * width + y; // wxh = width * height = d * d\n",
        "\n",
        "    x = nz_voxels / (dims[0]*dims[1])\n",
        "    zwpy = nz_voxels % (dims[0]*dims[1]) # z*w + y\n",
        "    z = zwpy / dims[0]\n",
        "    y = zwpy % dims[0]\n",
        "    if fix_coords:\n",
        "        data = np.vstack((x, y, z))\n",
        "        axis_order = 'xyz'\n",
        "    else:\n",
        "        data = np.vstack((x, z, y))\n",
        "        axis_order = 'xzy'\n",
        "\n",
        "    #return Voxels(data, dims, translate, scale, axis_order)\n",
        "    return Voxels(np.ascontiguousarray(data), dims, translate, scale, axis_order)\n",
        "\n",
        "def dense_to_sparse(voxel_data, dtype=int):\n",
        "    \"\"\" From dense representation to sparse (coordinate) representation.\n",
        "    No coordinate reordering.\n",
        "    \"\"\"\n",
        "    if voxel_data.ndim!=3:\n",
        "        raise ValueError('voxel_data is wrong shape; should be 3D array.')\n",
        "    return np.asarray(np.nonzero(voxel_data), dtype)\n",
        "\n",
        "def sparse_to_dense(voxel_data, dims, dtype=bool):\n",
        "    if voxel_data.ndim!=2 or voxel_data.shape[0]!=3:\n",
        "        raise ValueError('voxel_data is wrong shape; should be 3xN array.')\n",
        "    if np.isscalar(dims):\n",
        "        dims = [dims]*3\n",
        "    dims = np.atleast_2d(dims).T\n",
        "    # truncate to integers\n",
        "    xyz = voxel_data.astype(np.int)\n",
        "    # discard voxels that fall outside dims\n",
        "    valid_ix = ~np.any((xyz < 0) | (xyz >= dims), 0)\n",
        "    xyz = xyz[:,valid_ix]\n",
        "    out = np.zeros(dims.flatten(), dtype=dtype)\n",
        "    out[tuple(xyz)] = True\n",
        "    return out\n",
        "\n",
        "#def get_linear_index(x, y, z, dims):\n",
        "    #\"\"\" Assuming xzy order. (y increasing fastest.\n",
        "    #TODO ensure this is right when dims are not all same\n",
        "    #\"\"\"\n",
        "    #return x*(dims[1]*dims[2]) + z*dims[1] + y\n",
        "\n",
        "def write(voxel_model, fp):\n",
        "    \"\"\" Write binary binvox format.\n",
        "\n",
        "    Note that when saving a model in sparse (coordinate) format, it is first\n",
        "    converted to dense format.\n",
        "\n",
        "    Doesn't check if the model is 'sane'.\n",
        "\n",
        "    \"\"\"\n",
        "    if voxel_model.data.ndim==2:\n",
        "        # TODO avoid conversion to dense\n",
        "        dense_voxel_data = sparse_to_dense(voxel_model.data, voxel_model.dims)\n",
        "    else:\n",
        "        dense_voxel_data = voxel_model.data\n",
        "\n",
        "    fp.write('#binvox 1\\n')\n",
        "    fp.write('dim '+' '.join(map(str, voxel_model.dims))+'\\n')\n",
        "    fp.write('translate '+' '.join(map(str, voxel_model.translate))+'\\n')\n",
        "    fp.write('scale '+str(voxel_model.scale)+'\\n')\n",
        "    fp.write('data\\n')\n",
        "    if not voxel_model.axis_order in ('xzy', 'xyz'):\n",
        "        raise ValueError('Unsupported voxel model axis order')\n",
        "\n",
        "    if voxel_model.axis_order=='xzy':\n",
        "        voxels_flat = dense_voxel_data.flatten()\n",
        "    elif voxel_model.axis_order=='xyz':\n",
        "        voxels_flat = np.transpose(dense_voxel_data, (0, 2, 1)).flatten()\n",
        "\n",
        "    # keep a sort of state machine for writing run length encoding\n",
        "    state = voxels_flat[0]\n",
        "    ctr = 0\n",
        "    for c in voxels_flat:\n",
        "        if c==state:\n",
        "            ctr += 1\n",
        "            # if ctr hits max, dump\n",
        "            if ctr==255:\n",
        "                fp.write(chr(state))\n",
        "                fp.write(chr(ctr))\n",
        "                ctr = 0\n",
        "        else:\n",
        "            # if switch state, dump\n",
        "            fp.write(chr(state))\n",
        "            fp.write(chr(ctr))\n",
        "            state = c\n",
        "            ctr = 1\n",
        "    # flush out remainders\n",
        "    if ctr > 0:\n",
        "        fp.write(chr(state))\n",
        "        fp.write(chr(ctr))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import doctest\n",
        "    doctest.testmod()\n"
      ],
      "metadata": {
        "id": "HVEA2DO_RSCo",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c183f770-5ba3-4b77-e6b2-fb21ce8ce3fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.10/doctest.py\", line 1501, in run\n",
            "    sys.settrace(save_trace)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Wandb Install\n",
        "\n",
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Xrj20rhTI6d",
        "outputId": "1a4a4223-4c68-4dd7-d1bf-79d179073d23",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.1-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.21.1-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.7/201.7 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=6b3155647096616a35d0bbe18542addb37b2528314a1d06389c4862f23ac763a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.21.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Wandb Imports\n",
        "\n",
        "import wandb\n",
        "#wandb.login(key=\"d57a272a54db383f4776fb3f28f72e9b76a1dc79\")\n",
        "wandb.login()\n",
        "\n",
        "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "_auAY4Eu2ztk",
        "outputId": "735a7cd2-a3c3-45fd-e672-9c4f7fe84f54"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv3D, concatenate, MaxPool3D, Dense, Activation, MaxPooling3D, Dropout, Flatten, Reshape, BatchNormalization, AveragePooling3D, Input"
      ],
      "metadata": {
        "id": "Pb38axB30xuS",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load numpy array\n",
        "\n",
        "loaded = np.load('/content/gdrive/MyDrive/Research/voxelized_64_parts_0.npz')\n",
        "models = loaded['a']\n",
        "scale = loaded['b']\n",
        "y_labels = loaded['c']"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AaTbAPQRKTgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot labels\n",
        "\n",
        "plt.hist(y_labels, [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
        "plt.xlabel(\"Label Score\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Raw Data Capped at Twenty\")\n",
        "plt.show()\n",
        "\n",
        "plt.hist(y_labels, 500)\n",
        "plt.xlabel(\"Label Score\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Raw Data\")\n",
        "plt.show()\n",
        "\n",
        "plt.hist(y_labels, [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,500])\n",
        "plt.xlabel(\"Label Score\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "plt.hist(y_labels, [0,5,300])\n",
        "plt.xlabel(\"Label Score\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "norm_y_labels = np.log(y_labels)/6\n",
        "plt.hist(norm_y_labels)\n",
        "plt.xlabel(\"Label Score (log)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Normalized Data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6HlFosw9qPY3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Processing Labels\n",
        "#print(len(y_labels))\n",
        "y_labels_new = np.zeros((len(y_labels),2))\n",
        "for i in range(len(y_labels)):\n",
        "  if y_labels[i] >= 5:\n",
        "    #print(\"here\")\n",
        "    y_labels_new[i,:] = [0,1]\n",
        "  else:\n",
        "    y_labels_new[i,:] = [1,0]\n",
        "#print(y_labels_new)"
      ],
      "metadata": {
        "id": "udI6ZpP9r-y3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GPU availability check\n",
        "\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  print(torch.device('cuda'))\n",
        "else:\n",
        "  print(torch.device('cpu'))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "U1W7wpnsMSXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3D CNN\n",
        "dims = 64\n",
        "model_3D_part_input = Input(shape=(dims, dims, dims, 1), name='Input_3D_part')\n",
        "\n",
        "model3D_1 = Conv3D(32, kernel_size=(3, 3, 3), activation='relu')(model_3D_part_input)\n",
        "\n",
        "model3D_2 = MaxPooling3D(pool_size=(2, 2, 2),strides=2)(model3D_1)\n",
        "\n",
        "model3D_3 = Conv3D(64, kernel_size=(3, 3, 3), activation='relu')(model3D_2)\n",
        "\n",
        "model3D_4 = MaxPooling3D(pool_size=(2, 2, 2),strides=2)(model3D_3)\n",
        "\n",
        "model3D_5 = Conv3D(64, kernel_size=(3, 3, 3), activation='relu')(model3D_4)\n",
        "\n",
        "model3D_6 = MaxPooling3D(pool_size=(2, 2, 2),strides=2)(model3D_5)\n",
        "\n",
        "model3D_7 = Flatten()(model3D_6)\n",
        "\n",
        "model3D_8 = Dense(32, activation='relu')(model3D_7)\n",
        "\n",
        "model3D_9 = Dense(16, activation='relu')(model3D_8)\n",
        "\n",
        "model3D_10 = Dense(2, activation='softmax')(model3D_9)\n",
        "\n",
        "model_final = Model(inputs=[model_3D_part_input],outputs=[model3D_10], name = \"final_model\")\n",
        "\n",
        "#Model Details\n",
        "model_final.summary()\n",
        "#merged = Concatenate([model, scale])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gJQF8KjdIXQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Wandb Initialization\n",
        "\n",
        "LR = 0.001\n",
        "SpE = 200\n",
        "bSize = 32\n",
        "Enum = 20\n",
        "# Start a run, tracking hyperparameters\n",
        "wandb.init(\n",
        "    # set the wandb project where this run will be logged\n",
        "    project=\"3D_CNN_printability\",\n",
        "\n",
        "    # track hyperparameters and run metadata with wandb.config\n",
        "    config={\n",
        "        \"optimizer\": \"adam\",\n",
        "        \"loss\": \"mean_absolute_error\",\n",
        "        \"epoch\": Enum,\n",
        "        \"batch_size\": bSize,\n",
        "        \"steps_per_epoch\": SpE,\n",
        "        \"learning_rate\": LR,\n",
        "        \"classification\": 1\n",
        "    }\n",
        ")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ugWp6gZq01Tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train-Test Data Split\n",
        "print(models.shape)\n",
        "models_train, models_test, scale_train, scale_test, y_train, y_test = train_test_split(models, scale, y_labels_new, test_size=0.2, shuffle=True)\n",
        "print(models_train.shape)\n",
        "print(models_test.shape)\n",
        "print(scale_train.shape)\n",
        "print(scale_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LDsbDcq1IZbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training Model\n",
        "#new_learning_rate = 0.01 \n",
        "#my_optimizer.lr.assign(new_learning_rate)\n",
        "\n",
        "model_final.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model_final.fit(models_train, y_train, epochs=Enum, batch_size=bSize, steps_per_epoch=SpE, callbacks=[\n",
        "                      WandbMetricsLogger(log_freq=5),\n",
        "                      WandbModelCheckpoint(\"models\")\n",
        "                    ])"
      ],
      "metadata": {
        "id": "M3Ij9CWeOAwf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluate Model\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model_final.evaluate(models_test, y_test, callbacks=[\n",
        "                      WandbMetricsLogger(log_freq=5),\n",
        "                      WandbModelCheckpoint(\"models2\")\n",
        "                    ])\n",
        "#wandb.log({\"acc\": accuracy, \"loss\": loss})\n",
        "#wandb.log({\"loss\": loss})\n",
        "print('Test loss:', loss)"
      ],
      "metadata": {
        "id": "6f4G_K7WOEzG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Finish Wandb\n",
        "\n",
        "# [optional] finish the wandb run, necessary in notebooks\n",
        "wandb.finish()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2W18ryRqvJPB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}